% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lightgbm_train.R
\name{LightGBM}
\alias{LightGBM}
\title{R6 LightGBM function}
\description{
A wrapper around the lightgbm python api.
}
\references{
\url{https://lightgbm.readthedocs.io}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{num_boost_round}}{Number of training rounds.}

\item{\code{early_stopping_rounds}}{A integer. Activates early stopping.
Requires at least one validation data and one metric. If there's
more than one, will check all of them except the training data.
Returns the model with (best_iter + early_stopping_rounds).
If early stopping occurs, the model will have 'best_iter' field.}

\item{\code{categorical_feature}}{A list of str or int. Type int represents
index, type str represents feature names.}

\item{\code{train_data}}{A data.table object holding the training data.}

\item{\code{train_label}}{A vector holding the training labels.}

\item{\code{valid_data}}{A data.table object holding the validation data.}

\item{\code{valid_label}}{A vector holding the validation labels.}

\item{\code{label_names}}{The unique label names in classification tasks.}

\item{\code{trans_tar}}{The transfrom_target instance.}

\item{\code{param_set}}{The lightgbm parameters.}

\item{\code{nrounds_by_cv}}{A logical. Calculate the best nrounds by using
the `lgb.cv` before the training step}

\item{\code{cv_folds}}{The number of cross validation folds, when setting
`nrounds_by_cv` = TRUE (default: 5).}

\item{\code{cv_model}}{The cross validation model.}

\item{\code{model}}{The trained lightgbm model.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{LightGBM$new()}}
\item \href{#method-init_data}{\code{LightGBM$init_data()}}
\item \href{#method-train_cv}{\code{LightGBM$train_cv()}}
\item \href{#method-train}{\code{LightGBM$train()}}
\item \href{#method-predict}{\code{LightGBM$predict()}}
\item \href{#method-importance}{\code{LightGBM$importance()}}
\item \href{#method-valids}{\code{LightGBM$valids()}}
\item \href{#method-clone}{\code{LightGBM$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\subsection{Method \code{new()}}{
The data_preprocessing function.


The initialize function.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LightGBM$new()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-init_data"></a>}}
\subsection{Method \code{init_data()}}{
Initialize dataset function.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LightGBM$init_data(dataset, target_col, id_col = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{dataset}}{A data.table object. The dataset used for training.}

\item{\code{target_col}}{A character string. The name of the target column.}

\item{\code{id_col}}{(optional) A character string. The name of the ID column
(default: NULL).}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-train_cv"></a>}}
\subsection{Method \code{train_cv()}}{
The train_cv function
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LightGBM$train_cv()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-train"></a>}}
\subsection{Method \code{train()}}{
The train function
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LightGBM$train()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-predict"></a>}}
\subsection{Method \code{predict()}}{
The predict function.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LightGBM$predict(newdata)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{newdata}}{A data.table object holding the data which should be
predicted.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
All arguments are passed to the predict function of the created
  lightgbm python model by using R's reticulate package.
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-importance"></a>}}
\subsection{Method \code{importance()}}{
The importance function.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LightGBM$importance(view_max = 20)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{view_max}}{An integer. The maximum number of features to be
shown in the importance plot (default: 20).}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
Exports the model's variable importance.
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-valids"></a>}}
\subsection{Method \code{valids()}}{
The valids function
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LightGBM$valids(validset)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{validset}}{A data.table object, containing the validation data.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The function can be used to provide a subsample to the data
  to the lightgbm's train function's `valids` argument. This is e.g.
  needed, when the argument `early_stopping_rounds` is used.
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LightGBM$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
